{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71295c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# for NLP related tasks\n",
    "import spacy\n",
    "global nlp\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "# for mongodb operations\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# saving model as pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a58a5b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape --> (136, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add 5 kg of Biscuits</td>\n",
       "      <td>ham</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>play music</td>\n",
       "      <td>spam</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add 2 litres of milk</td>\n",
       "      <td>ham</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who is prime minister</td>\n",
       "      <td>spam</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remove 1kg of fruits</td>\n",
       "      <td>ham</td>\n",
       "      <td>remove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text label  action\n",
       "0   add 5 kg of Biscuits   ham     add\n",
       "1             play music  spam    play\n",
       "2   add 2 litres of milk   ham     add\n",
       "3  who is prime minister  spam    none\n",
       "4   remove 1kg of fruits   ham  remove"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/Users/DAG9KOR/Downloads/ProjectMulticlasstextclassification/inventory.csv')\n",
    "print('Shape -->',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e108864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20                 please sing a song for me\n",
       "94       provide exisitng items in inventory\n",
       "54        show me what is there in inventory\n",
       "45    display the current items in inventory\n",
       "12           add 2 kg bread in food category\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7664ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.617647\n",
       "spam    0.382353\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d469650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "  \n",
    "  #remove user mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
    "  \n",
    "  #remove hashtags\n",
    "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
    "  \n",
    "  #remove links\n",
    "    text = re.sub(r'http\\S+', '', text)  \n",
    "\n",
    "  #convering text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "  # fetch only words\n",
    "    text = re.sub(\"[^a-z]+\", \" \", text)\n",
    "\n",
    "  # removing extra spaces\n",
    "    text=re.sub(\"[\\s]+\",\" \",text)\n",
    "  \n",
    "  # creating doc object\n",
    "    doc=nlp(text)\n",
    "\n",
    "  # remove stopwords and lemmatize the text\n",
    "    tokens=[token.lemma_ for token in doc if(token.is_stop==False)]\n",
    "  \n",
    "  #join tokens by space\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32e6fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform text cleaning\n",
    "df['clean_text']= df['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04d11e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121               exist item inventory\n",
       "19             highest rate imdb movie\n",
       "16          add kg bread food category\n",
       "32       add packet milk food category\n",
       "91     display exisitng item inventory\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bdd89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text   = df['clean_text'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5d3a42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'spam', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8df73f",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "345ecd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#define label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#fit and transform target strings to a numbers\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92dc201d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ea75366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c52a8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = le.inverse_transform([0,1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "78f939dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into train and validation set\n",
    "x_train,x_val,y_train,y_val=train_test_split(text, labels,stratify=labels, test_size=0.30, random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bab0a56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (95,) y_train: (95,)\n",
      "x_val: (41,) y_val: (41,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train:',x_train.shape,'y_train:',y_train.shape)\n",
    "print('x_val:',x_val.shape,'y_val:',y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "972d6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f09e74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6645590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39da183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word_vectorizer,open(\"vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ac626bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95x69 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 296 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF vectors for Train Set\n",
    "train_word_features = word_vectorizer.transform(x_train)\n",
    "train_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77167481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41x69 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF vectors for Validation Set\n",
    "val_word_features = word_vectorizer.transform(x_val)\n",
    "val_word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285ee39",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "867695d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42f64f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "nb_model=MultinomialNB().fit(train_word_features,y_train)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad2f8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to pickle file\n",
    "pickle.dump(nb_model, open('nb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7551eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read model from pickle file\n",
    "pickled_model = pickle.load(open('nb_model.pkl', 'rb'))\n",
    "pickled_model.predict(train_word_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25d14d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for train set\n",
    "train_pred_nb=nb_model.predict(train_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6eb30069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a619535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 0.9681260283298977\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on Training Set\n",
    "f1_nb_train = f1_score(y_train,train_pred_nb,average=\"weighted\")\n",
    "print(\"F1-score on Train Set:\",f1_nb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a1ba94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Validation Set: 0.9251154450386405\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for validation set\n",
    "val_pred_nb=nb_model.predict(val_word_features)\n",
    "\n",
    "# Evaluating on Validation Set\n",
    "f1_nb_val = f1_score(y_val,val_pred_nb,average=\"weighted\")\n",
    "print(\"F1-score on Validation Set:\",f1_nb_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6b799",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "495813df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0994bd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "lr_model=LogisticRegression().fit(train_word_features, y_train)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78a070d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for train set\n",
    "train_pred_lr=lr_model.predict(train_word_features)\n",
    "train_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a246d143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on Training Set\n",
    "f1_lr_train = f1_score(y_train,train_pred_lr,average=\"weighted\")\n",
    "print(\"F1-score on Train Set:\",f1_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59942742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Validation Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for validation set\n",
    "val_pred_lr=lr_model.predict(val_word_features)\n",
    "\n",
    "# Evaluating on Validation Set\n",
    "f1_lr_val = f1_score(y_val,val_pred_lr,average=\"weighted\")\n",
    "print(\"F1-score on Validation Set:\", f1_lr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0e168",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f90991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "311fcb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_model = lsvc.fit(train_word_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24e5af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_lsvc = lsvc.predict(val_word_features)\n",
    "preds_train_lsvc = lsvc.predict(train_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3c04754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 1.0\n",
      "F1-score on Validation Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score on Train Set:\",f1_score(y_train,preds_train_lsvc,average=\"weighted\"))\n",
    "print(\"F1-score on Validation Set:\",f1_score(y_val,preds_val_lsvc,average=\"weighted\"))\n",
    "\n",
    "train_lsvc_f1 = f1_score(y_train,preds_train_lsvc,average=\"weighted\")\n",
    "val_lsvc_f1 = f1_score(y_val,preds_val_lsvc,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc48db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "538fde33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl = xgb.XGBClassifier()\n",
    "xgb_cl.fit(train_word_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa531e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = xgb_cl.predict(val_word_features)\n",
    "preds_train = xgb_cl.predict(train_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "759ea114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on Train Set: 0.968502394025105\n",
      "F1-score on Validation Set: 0.9754554851051357\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score on Train Set:\",f1_score(y_train,preds_train,average=\"weighted\"))\n",
    "print(\"F1-score on Validation Set:\",f1_score(y_val,preds_val,average=\"weighted\"))\n",
    "\n",
    "train_xg_f1 = f1_score(y_train,preds_train,average=\"weighted\")\n",
    "val_xg_f1 = f1_score(y_val,preds_val,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca1d44",
   "metadata": {},
   "source": [
    "## Model Building Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c8cfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = {\"model\":['Naive Bayes','Logistic Regression','Linear SVC','XGBooster'],\n",
    "         'train_F1_score':[f1_nb_train,f1_lr_train,train_lsvc_f1,train_xg_f1],\n",
    "         'val_F1_score':[f1_nb_val,f1_lr_val,val_lsvc_f1,val_xg_f1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "312d43dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_F1_score</th>\n",
       "      <th>val_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>0.925115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBooster</td>\n",
       "      <td>0.968502</td>\n",
       "      <td>0.975455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_F1_score  val_F1_score\n",
       "0          Naive Bayes        0.968126      0.925115\n",
       "1  Logistic Regression        1.000000      1.000000\n",
       "2           Linear SVC        1.000000      1.000000\n",
       "3            XGBooster        0.968502      0.975455"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.DataFrame(f1_df)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2adff",
   "metadata": {},
   "source": [
    "## Database operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4bcce600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input message 'provide the existing stocks' is valid\n",
      "The action from input message:  provide\n",
      "The following items are present in the inventory:\n",
      "\n",
      "          item  units  item_quantity\n",
      "0     Sandwich     kg            221\n",
      "1        Wheat     kg              8\n",
      "2       Fruits     kg              2\n",
      "3         Salt     kg              2\n",
      "4    Detergent     kg              4\n",
      "5       Sweets     kg             18\n",
      "6        Sugar     kg             12\n",
      "7   Softdrinks  liter              0\n",
      "8         Milk  liter             84\n",
      "9         Milk     NA             48\n",
      "10       Sugar     NA              0\n",
      "11       Wheat     NA              0\n",
      "12    Biscuits     kg             56\n",
      "There is no action from input message\n"
     ]
    }
   ],
   "source": [
    "#input_message = 'remove 25 kg of Sandwich from inventory'\n",
    "#input_message = 'add 20 kg of Biscuits to stocks inventory'\n",
    "#input_message = 'add 5 kg of Fish to food inventory'\n",
    "#input_message = 'what is the gdp of india'\n",
    "#input_message = 'please add me to your fb account'\n",
    "#input_message = \"update 12 kg of Sugar to food category\"\n",
    "#input_message = \"update inventory by 5 kg of Sugar\"\n",
    "#input_message = 'what do u offer for me'\n",
    "input_message = 'provide the existing stocks'\n",
    "\n",
    "\n",
    "# predicting the input message label\n",
    "processed = text_cleaner(input_message)\n",
    "vector = word_vectorizer.transform([processed])\n",
    "pred = pickled_model.predict(vector)\n",
    "    \n",
    "label = le.inverse_transform(np.array(pred))[0]\n",
    "\n",
    "# available menu\n",
    "menu = ['Biscuits','Milk','Sandwich','Fruits','Wheat','Sugar','Salt','Bread','Detergent','Softdrinks','Sweets']\n",
    "\n",
    "# actions that can be performed with inventory\n",
    "add_action = ['add','append','push']\n",
    "remove_action = ['remove','delete','subtract']\n",
    "display_action = ['display','provide','show','offer','retrieve','extract','get']\n",
    "give_action = ['give','dispatch','dispense']\n",
    "\n",
    "json = {}\n",
    "\n",
    "#try:\n",
    "\n",
    "if label == valid:\n",
    "    print(f\"The input message '{input_message}' is valid\")\n",
    "\n",
    "    # database connection\n",
    "    uri = \"mongodb://dhanu:dhanu@localhost:27072/?authSource=admin\"\n",
    "    client = MongoClient(uri)\n",
    "    db = client['inventory']\n",
    "    collection = db['products']\n",
    "\n",
    "    # spaCy object creation\n",
    "    doc = nlp(input_message)\n",
    "\n",
    "    # identifying the quantity entities using NER\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'QUANTITY':\n",
    "            item_quantity = re.search('\\d+', ent.text)\n",
    "            item_quantity = item_quantity.group()\n",
    "            json['item_quantity'] = int(item_quantity)\n",
    "            #print(\"the quantity----->\",json['item_quantity'])\n",
    "            item_units = re.search('\\D+', ent.text)\n",
    "            item_units = str(item_units.group())\n",
    "            json['units'] = item_units.strip()\n",
    "            #print(\"The units are ----->\",json['units'])\n",
    "\n",
    "        elif ent.label_ == 'CARDINAL':\n",
    "            item_quantity = int(ent.text)\n",
    "            #print(\"The cardinal number--->\",item_quantity)\n",
    "            json['item_quantity'] = item_quantity\n",
    "            json['units'] = 'NA'\n",
    "\n",
    "\n",
    "    # extracting the item from input message\n",
    "    for token in doc:\n",
    "        #print(token)\n",
    "        for i in menu:\n",
    "            if token.text.lower() == i.lower():\n",
    "                item1 = menu[menu.index(i)]\n",
    "                json['item'] = item1\n",
    "\n",
    "\n",
    "    # identifying the action from input message\n",
    "    action = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            action.append(token.text)\n",
    "\n",
    "    print(\"The action from input message: \",action[0])\n",
    "\n",
    "\n",
    "    # display action processing\n",
    "    if action[0] in display_action:\n",
    "        print(\"The following items are present in the inventory:\\n\")\n",
    "        cursor = collection.find({},{'_id':0})\n",
    "        item_list = []\n",
    "        for itr in cursor:\n",
    "            item_list.append(itr)\n",
    "\n",
    "        df_items = pd.DataFrame(item_list)\n",
    "        print(df_items)\n",
    "\n",
    "    # input products check in the inventory\n",
    "    elif json.get('item') == None:\n",
    "        print(\"The specified item from input message is not in the Menu. The available menu: \\n\", menu)\n",
    "    else:\n",
    "        print(\"The metadata extracted from input message:\\n\", json)\n",
    "\n",
    "    # add action process\n",
    "    if action[0] in add_action:\n",
    "\n",
    "        if json['units'] == 'kg' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'kg'}\n",
    "\n",
    "            # quantity extracted from input message\n",
    "            quantity = {'$inc':{'item_quantity':json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        elif json['units'] == 'liter' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'liter'}\n",
    "\n",
    "            # quantity updation\n",
    "            quantity = {'$inc':{'item_quantity':json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        elif json['units'] == 'NA' and json.get('item'):\n",
    "\n",
    "            search_filter = {'item':json['item'], 'units':'NA'}\n",
    "\n",
    "            # quantity updation\n",
    "            quantity = {'$inc':{'item_quantity':json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "            \n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        else:\n",
    "            print(\"The product from input message was not available in inventory\")\n",
    "\n",
    "    # delete action process\n",
    "    elif action[0] in remove_action:\n",
    "\n",
    "        if json['units'] == 'kg' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'kg'}\n",
    "\n",
    "            # quantity extracted from input message\n",
    "            quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        elif json['units'] == 'liter' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'liter'}\n",
    "\n",
    "            # quantity extracted from input message\n",
    "            quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        elif json['units'] == 'NA' and json.get('item'):\n",
    "\n",
    "            search_filter = {'item':json['item'], 'units':'NA'}\n",
    "\n",
    "            # quantity updation\n",
    "            quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "\n",
    "            # database operation\n",
    "            collection.update_one(search_filter, quantity, upsert=True)\n",
    "\n",
    "            print(\"The items are updated in database\")\n",
    "\n",
    "        else:\n",
    "            print(\"The product from input message was not available in inventory\")\n",
    "\n",
    "    # dispatch action processing\n",
    "\n",
    "\n",
    "    elif action[0] in give_action:\n",
    "\n",
    "        if json['units'] == 'kg' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'kg'}\n",
    "\n",
    "            # fetching the documents from db\n",
    "            cursor = collection.find_one(search_filter)\n",
    "            if cursor:\n",
    "                print(\"Available {} stock: {} {}\".format(json['item'],cursor['item_quantity'],json['units']))\n",
    "                db_quantity = cursor['item_quantity']\n",
    "                \n",
    "                if json['item_quantity'] > db_quantity:\n",
    "                    print(\"Insufficient items in inventory\")\n",
    "                else:\n",
    "                    print(\"The items are available and ready to dispense\")\n",
    "                    quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "                    collection.update_one(search_filter, quantity, upsert=True)\n",
    "            else:\n",
    "                print(f\"The desired item '{json['item']}' is not available. Please add to inventory\")\n",
    "            \n",
    "        elif json['units'] == 'liter' and json.get('item'):\n",
    "\n",
    "            # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'liter'}\n",
    "\n",
    "            # fetching the documents from db\n",
    "            cursor = collection.find_one(search_filter)\n",
    "            if cursor:\n",
    "                print(\"Available {} stock: {} {}\".format(json['item'],cursor['item_quantity'],json['units']))\n",
    "                db_quantity = cursor['item_quantity']\n",
    "                \n",
    "                if json['item_quantity'] > db_quantity:\n",
    "                    print(\"Insufficient items in inventory\")\n",
    "                else:\n",
    "                    print(\"The items are available and ready to dispense\")\n",
    "                    quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "                    collection.update_one(search_filter, quantity, upsert=True)\n",
    "            else:\n",
    "                print(f\"The desired item '{json['item']}' is not available. Please add to inventory\")\n",
    "\n",
    "        elif json['units'] == 'NA' and json.get('item'):\n",
    "\n",
    "             # filter for searching the item\n",
    "            search_filter = {'item':json['item'], 'units':'NA'}\n",
    "            \n",
    "            # fetching the documents from db\n",
    "            cursor = collection.find_one(search_filter)\n",
    "\n",
    "            if cursor:\n",
    "                print(\"Available {} stock: {} \".format(json['item'],cursor['item_quantity']))\n",
    "                db_quantity = cursor['item_quantity']\n",
    "                \n",
    "                if json['item_quantity'] > db_quantity:\n",
    "                    print(\"Insufficient items in inventory\")\n",
    "                else:\n",
    "                    print(\"The items are available and ready to dispense\")\n",
    "                    quantity = {'$inc':{'item_quantity':-json['item_quantity']}}\n",
    "                    collection.update_one(search_filter, quantity, upsert=True)\n",
    "            else:\n",
    "                print(f\"The desired item '{json['item']}' is not available. Please add to inventory\")\n",
    "\n",
    "    else:\n",
    "        print(\"There is no action from input message\")\n",
    "\n",
    "else:\n",
    "    print(f\"The input message '{input_message}' was not valid\")\n",
    "\n",
    "# except Exception as error:\n",
    "#     print(\"The exception is --->\", error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "030fc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('63c54ca3a2389fc49b021ed3'), 'item': 'Sandwich', 'units': 'kg', 'item_quantity': 221}\n",
      "{'_id': ObjectId('63c7e7f76213d5f5b7afa7eb'), 'item': 'Wheat', 'units': 'kg', 'item_quantity': 8}\n",
      "{'_id': ObjectId('63c7e9d66213d5f5b7afa860'), 'item': 'Fruits', 'units': 'kg', 'item_quantity': 2}\n",
      "{'_id': ObjectId('63c7eba36213d5f5b7afa8c5'), 'item': 'Salt', 'units': 'kg', 'item_quantity': 2}\n",
      "{'_id': ObjectId('63c7eda76213d5f5b7afa936'), 'item': 'Detergent', 'units': 'kg', 'item_quantity': 4}\n",
      "{'_id': ObjectId('63c7ef506213d5f5b7afa9a1'), 'item': 'Sweets', 'units': 'kg', 'item_quantity': 18}\n",
      "{'_id': ObjectId('63c8d73c6213d5f5b7afacca'), 'item': 'Sugar', 'units': 'kg', 'item_quantity': 12}\n",
      "{'_id': ObjectId('63c925926213d5f5b7afb5f9'), 'item': 'Softdrinks', 'units': 'liter', 'item_quantity': 0}\n",
      "{'_id': ObjectId('63c925ad6213d5f5b7afb608'), 'item': 'Milk', 'units': 'liter', 'item_quantity': 84}\n",
      "{'_id': ObjectId('63c93adf6213d5f5b7afb899'), 'item': 'Milk', 'units': 'NA', 'item_quantity': 48}\n",
      "{'_id': ObjectId('63c94e82069026c63931ad4c'), 'item': 'Sugar', 'units': 'NA', 'item_quantity': 0}\n",
      "{'_id': ObjectId('63c94ef5069026c63931ad51'), 'item': 'Wheat', 'units': 'NA', 'item_quantity': 0}\n",
      "{'_id': ObjectId('63c950a86213d5f5b7afbd1c'), 'item': 'Biscuits', 'units': 'kg', 'item_quantity': 56}\n"
     ]
    }
   ],
   "source": [
    "# retrieving the documents from database\n",
    "cursor = collection.find()\n",
    "for itr in cursor:\n",
    "    print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88f8e74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "# finding the desired document\n",
    "search_filter = {'item':'Sandwich', 'units':'NA'}\n",
    "cursor = collection.find_one(search_filter)\n",
    "if cursor:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7520d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342241c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
